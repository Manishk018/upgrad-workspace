{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to tokenise words\n",
    "def words(document):\n",
    "    \"Convert text to lower case and tokenise the document\"\n",
    "    return re.findall(r'\\w+', document.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a frequency table of all the words of the document\n",
    "all_words = Counter(words(open('big.txt').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check frequency of a random word, say, 'chair'\n",
    "all_words['chair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 79809),\n",
       " ('of', 40024),\n",
       " ('and', 38312),\n",
       " ('to', 28765),\n",
       " ('in', 22023),\n",
       " ('a', 21124),\n",
       " ('that', 12512),\n",
       " ('he', 12401),\n",
       " ('was', 11410),\n",
       " ('it', 10681)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at top 10 frequent words\n",
    "all_words.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edits_one(word):\n",
    "    \"Create all edits that are one edit away from `word`.\"\n",
    "    alphabets    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])                   for i in range(len(word) + 1)]\n",
    "    deletes    = [left + right[1:]                       for left, right in splits if right]\n",
    "    inserts    = [left + c + right                       for left, right in splits for c in alphabets]\n",
    "    replaces   = [left + c + right[1:]                   for left, right in splits if right for c in alphabets]\n",
    "    transposes = [left + right[1] + right[0] + right[2:] for left, right in splits if len(right)>1]\n",
    "    return set(deletes + inserts + replaces + transposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edits_two(word):\n",
    "    \"Create all edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits_one(word) for e2 in edits_one(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    \"The subset of `words` that appear in the `all_words`.\"\n",
    "    return set(word for word in words if word in all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def possible_corrections(word):\n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits_one(word)) or known(edits_two(word)) or [word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob(word, N=sum(all_words.values())): \n",
    "    \"Probability of `word`: Number of appearances of 'word' / total number of tokens\"\n",
    "    return all_words[word] / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "{'monneuy', 'conney', 'monoey', 'monneey', 'mojnney', 'monnyey', 'monnwey', 'monneyt', 'motnney', 'monnet', 'monnay', 'monbney', 'monfey', 'xmonney', 'mownney', 'morney', 'moinney', 'moiney', 'monvey', 'moynney', 'monnea', 'moniney', 'mopney', 'monneyg', 'mongey', 'monney', 'umonney', 'monnepy', 'vmonney', 'monneyy', 'mdnney', 'monnezy', 'monneyp', 'monnoy', 'movney', 'mononey', 'mjnney', 'monwey', 'moenney', 'bmonney', 'monnef', 'monnpy', 'money', 'ymonney', 'moznney', 'qonney', 'myonney', 'honney', 'emonney', 'monnye', 'mnnney', 'monnvy', 'msonney', 'mtonney', 'monnfey', 'mtnney', 'tmonney', 'monnpey', 'monnky', 'sonney', 'mobney', 'wmonney', 'mgonney', 'monyey', 'monneyf', 'ponney', 'motney', 'mvnney', 'manney', 'monuney', 'monnrey', 'monned', 'monneq', 'monnek', 'monneg', 'monjey', 'monnxy', 'moncey', 'monnuey', 'monnex', 'jmonney', 'monneb', 'monneym', 'monne', 'nmonney', 'monneya', 'mwonney', 'nonney', 'monneqy', 'monnaey', 'mohnney', 'moaney', 'munney', 'monneyo', 'mbonney', 'monnely', 'monnoey', 'monnejy', 'monqney', 'monnuy', 'monndy', 'qmonney', 'monnqey', 'montney', 'monnvey', 'menney', 'modney', 'moneny', 'monneby', 'monnny', 'monnzey', 'lonney', 'monny', 'monncey', 'monkey', 'monneye', 'konney', 'monnev', 'mconney', 'monneu', 'mocney', 'mqonney', 'monnehy', 'onney', 'vonney', 'monnfy', 'monnevy', 'monneny', 'monnec', 'monhey', 'rmonney', 'monneyr', 'monneiy', 'monnsy', 'moqney', 'moeney', 'monnei', 'yonney', 'monniy', 'monnly', 'monneyw', 'monnew', 'mmnney', 'mhonney', 'monneys', 'monhney', 'uonney', 'monneyx', 'modnney', 'donney', 'monnxey', 'monnedy', 'monnhy', 'mosnney', 'eonney', 'mzonney', 'monlney', 'monaey', 'monnery', 'monneyk', 'monneyu', 'monxney', 'mbnney', 'monnbey', 'monngey', 'mowney', 'monmey', 'monnen', 'monzey', 'cmonney', 'zonney', 'mrnney', 'ronney', 'mofnney', 'monnety', 'mxonney', 'omonney', 'mobnney', 'monnmy', 'monnry', 'mvonney', 'monvney', 'monnjy', 'mondney', 'momnney', 'oonney', 'mponney', 'molnney', 'monneyh', 'monqey', 'montey', 'moxney', 'mnney', 'zmonney', 'mounney', 'monzney', 'mosney', 'molney', 'meonney', 'mdonney', 'muonney', 'monxey', 'mogney', 'mozney', 'lmonney', 'mnoney', 'mouney', 'imonney', 'monnwy', 'mgnney', 'fonney', 'mohney', 'kmonney', 'monnexy', 'monneyd', 'monneyq', 'mwnney', 'monneyj', 'mnonney', 'monnsey', 'monneyn', 'wonney', 'monnzy', 'monuey', 'monneyb', 'mojney', 'monnjey', 'moncney', 'monrey', 'monnney', 'monneyc', 'monjney', 'monneay', 'monnkey', 'hmonney', 'gonney', 'monnee', 'monpey', 'monneh', 'monneoy', 'monbey', 'mcnney', 'moxnney', 'msnney', 'maonney', 'mionney', 'ionney', 'monnel', 'monngy', 'monnes', 'mxnney', 'monaney', 'monmney', 'mznney', 'monnecy', 'monner', 'jonney', 'xonney', 'mronney', 'dmonney', 'smonney', 'moyney', 'monnhey', 'mjonney', 'pmonney', 'mfnney', 'monnej', 'mqnney', 'monnmey', 'mlonney', 'mornney', 'amonney', 'monnemy', 'monkney', 'aonney', 'mondey', 'monnty', 'monnley', 'monnqy', 'monneyv', 'momney', 'moneney', 'mocnney', 'monrney', 'monfney', 'mopnney', 'monneyl', 'moknney', 'monpney', 'monsney', 'bonney', 'monyney', 'monncy', 'monnem', 'monniey', 'monndey', 'mkonney', 'monwney', 'omnney', 'monnez', 'mognney', 'fmonney', 'mhnney', 'mknney', 'monntey', 'mmonney', 'monsey', 'tonney', 'moniey', 'monnegy', 'monnep', 'monnefy', 'monneyz', 'monnyy', 'moonney', 'monnesy', 'monnby', 'moanney', 'gmonney', 'mofney', 'mlnney', 'monnewy', 'moqnney', 'monley', 'mongney', 'mpnney', 'monneyi', 'mokney', 'mynney', 'moneey', 'minney', 'mfonney', 'movnney', 'monneky', 'monneo', 'mooney'}\n",
      "{'emphasize'}\n"
     ]
    }
   ],
   "source": [
    "print(len(set(edits_one(\"monney\"))))\n",
    "print(edits_one(\"monney\"))\n",
    "print(possible_corrections(\"emfasize\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'monkey', 'money'}\n"
     ]
    }
   ],
   "source": [
    "print(known(edits_one(\"monney\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51013\n",
      "{'monkey', 'money'}\n"
     ]
    }
   ],
   "source": [
    "# Let's look at words that are two edits away\n",
    "print(len(set(edits_two(\"monney\"))))\n",
    "print(known(edits_one(\"monney\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'monkey', 'money'}\n"
     ]
    }
   ],
   "source": [
    "# Let's look at possible corrections of a word\n",
    "print(possible_corrections(\"monney\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002922233626303688\n",
      "5.378344097491451e-06\n"
     ]
    }
   ],
   "source": [
    "# Let's look at probability of a word\n",
    "print(prob(\"money\"))\n",
    "print(prob(\"monkey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check(word):\n",
    "    \"Print the most probable spelling correction for `word` out of all the `possible_corrections`\"\n",
    "    correct_word = max(possible_corrections(word), key=prob)\n",
    "    if correct_word != word:\n",
    "        return \"Did you mean \" + correct_word + \"?\"\n",
    "    else:\n",
    "        return \"Correct spelling.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you mean money?\n"
     ]
    }
   ],
   "source": [
    "# test spell check\n",
    "print(spell_check(\"monney\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upGrad NOUN NN\n",
      "is AUX VBZ\n",
      "teaching VERB VBG\n",
      "Data PROPN NNP\n",
      "Science PROPN NNP\n",
      "courses NOUN NNS\n",
      "to ADP IN\n",
      "the DET DT\n",
      "working VERB VBG\n",
      "professionals NOUN NNS\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# !python -m spacy download en\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"upGrad is teaching Data Science courses to the working professionals.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She   PRON\n",
      "wished   VERB\n",
      "she   PRON\n",
      "could   AUX\n",
      "desert   VERB\n",
      "him   PRON\n",
      "in   ADP\n",
      "the   DET\n",
      "desert   NOUN\n"
     ]
    }
   ],
   "source": [
    "tokens=nlp('She wished she could desert him in the desert')\n",
    "for token in tokens:\n",
    "    print(token.text, \" \", token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ContentUpgrad/Syntactic-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
