{"cells":[{"cell_type":"code","execution_count":11,"id":"bbcde453-fbc3-4b80-a663-01212599fa9c","metadata":{"id":"bbcde453-fbc3-4b80-a663-01212599fa9c"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","id":"173476da-ac46-435c-81bb-858825c1908d","metadata":{"id":"173476da-ac46-435c-81bb-858825c1908d"},"source":["## Part 1: Import the Housing data and do feature transformations"]},{"cell_type":"code","execution_count":12,"id":"999b20bb-ff06-47ce-9824-3431ade3d628","metadata":{"id":"999b20bb-ff06-47ce-9824-3431ade3d628","outputId":"c9961c6e-e367-44c1-8635-b7c6a62c4cb7"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bedrooms</th>\n","      <th>sqft_living</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>1340</td>\n","      <td>313000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>3650</td>\n","      <td>2384000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1930</td>\n","      <td>342000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2000</td>\n","      <td>420000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1940</td>\n","      <td>550000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   bedrooms  sqft_living    price\n","0         3         1340   313000\n","1         5         3650  2384000\n","2         3         1930   342000\n","3         3         2000   420000\n","4         4         1940   550000"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df= pd.read_csv('house_price_full.csv')\n","df.head()"]},{"cell_type":"code","execution_count":13,"id":"9ac1d055-4622-4fc9-a2a3-d463bcf8befd","metadata":{"id":"9ac1d055-4622-4fc9-a2a3-d463bcf8befd"},"outputs":[],"source":["X = df.copy()\n","# Remove target\n","Y = X.pop('price')\n","\n","# perform a scaler transform of the input data\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# perform log transformation of target variable (For Sandeep: Is this needed?)\n","Y = np.log(Y)"]},{"cell_type":"code","execution_count":14,"id":"82b4c4a9-00c6-42d5-aede-b01c0faeb61a","metadata":{"id":"82b4c4a9-00c6-42d5-aede-b01c0faeb61a","outputId":"14e3cdc8-62a0-4dce-c657-a6937a09b761"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.433198</td>\n","      <td>-0.753258</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.675735</td>\n","      <td>1.457330</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.433198</td>\n","      <td>-0.188649</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.433198</td>\n","      <td>-0.121661</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.621269</td>\n","      <td>-0.179079</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>494</th>\n","      <td>0.621269</td>\n","      <td>0.873582</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>1.675735</td>\n","      <td>2.299459</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>-0.433198</td>\n","      <td>-0.724549</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>-0.433198</td>\n","      <td>-0.179079</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>-0.433198</td>\n","      <td>-1.040347</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>499 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["            0         1\n","0   -0.433198 -0.753258\n","1    1.675735  1.457330\n","2   -0.433198 -0.188649\n","3   -0.433198 -0.121661\n","4    0.621269 -0.179079\n","..        ...       ...\n","494  0.621269  0.873582\n","495  1.675735  2.299459\n","496 -0.433198 -0.724549\n","497 -0.433198 -0.179079\n","498 -0.433198 -1.040347\n","\n","[499 rows x 2 columns]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df_scaled = pd.DataFrame(X)\n","df_scaled"]},{"cell_type":"code","execution_count":15,"id":"8034fbca-2081-4de3-9fd3-8e5d379b2cbf","metadata":{"id":"8034fbca-2081-4de3-9fd3-8e5d379b2cbf","outputId":"22931110-1276-44a7-e878-8d189355c9cc"},"outputs":[{"data":{"text/plain":["0      12.653958\n","1      14.684290\n","2      12.742566\n","3      12.948010\n","4      13.217674\n","         ...    \n","494    13.380102\n","495    13.764217\n","496    12.128111\n","497    12.721886\n","498    12.254863\n","Name: price, Length: 499, dtype: float64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["Y"]},{"cell_type":"markdown","id":"754adc57-4f6c-4b96-a348-77bd82a4b304","metadata":{"id":"754adc57-4f6c-4b96-a348-77bd82a4b304"},"source":["## Part 2: Create Model Using `keras`\n","\n","![](multiple_neurons.png)"]},{"cell_type":"code","execution_count":16,"id":"9e7e3de3-c446-4fbe-be67-08c1431450d5","metadata":{"id":"9e7e3de3-c446-4fbe-be67-08c1431450d5"},"outputs":[],"source":["from tensorflow import keras"]},{"cell_type":"code","execution_count":17,"id":"7bf2231d-a13c-4e82-aae9-597b3caae6c0","metadata":{"id":"7bf2231d-a13c-4e82-aae9-597b3caae6c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_2 (Dense)             (None, 2)                 6         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 9 (36.00 Byte)\n","Trainable params: 9 (36.00 Byte)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model = keras.Sequential(\n","    [\n","        keras.layers.Dense(\n","            2, activation=\"sigmoid\", input_shape=(X.shape[-1],)\n","        ),\n","        keras.layers.Dense(1, activation=\"linear\")\n","    ]\n",")\n","model.summary()"]},{"cell_type":"markdown","id":"304a97ac-488e-44cf-b86b-b6f44dc81d72","metadata":{"id":"304a97ac-488e-44cf-b86b-b6f44dc81d72"},"source":["```python\n","def random_init_params():\n","    w1 = tf.Variable(tf.random.uniform((2, 2)))\n","    b1 = tf.Variable(tf.random.uniform((1, 2)))\n","    w2 = tf.Variable(tf.random.uniform((2, 1)))\n","    b2 = tf.Variable(tf.random.uniform((1, 1)))\n","    return w1,b1,w2,b2\n","\n","\n","def forward_prop(x, w1, b1, w2, b2):\n","    z1 = tf.matmul(x,w1) + b1\n","    h1 = tf.math.sigmoid(z1)\n","    z2 = tf.matmul(h1,w2) + b2\n","    h2 = z2\n","    return h2\n","```"]},{"cell_type":"code","execution_count":18,"id":"867ac40d-01c2-4f93-8977-1a3a1b37b320","metadata":{"id":"867ac40d-01c2-4f93-8977-1a3a1b37b320"},"outputs":[],"source":["model.compile(\n","    optimizer=keras.optimizers.SGD(), loss=\"mean_squared_error\"\n",")"]},{"cell_type":"markdown","id":"78a51db7-4b84-4338-9745-ece25b503892","metadata":{"id":"78a51db7-4b84-4338-9745-ece25b503892"},"source":["```python\n","def train(x, y, w1, b1, w2, b2):\n","    y_true = y\n","    with tf.GradientTape() as g:\n","        y_pred = forward_prop(x, w1, b1, w2, b2)\n","\n","        # loss\n","        loss = 0.5*(y_true - y_pred)** 2\n","    \n","    #Gradient calculation  \n","    print(\"**************************************************\")\n","    print(\"GRADIENTS\")\n","    print(\"**************************************************\")\n","    gw1, gb1, gw2, gb2 = g.gradient(loss, [w1, b1, w2, b2])\n","    print(\" the gradient for 1st layer weights are:\\n\",gw1.numpy())\n","    print(\"--------------------------------------------------\")\n","    print(\" the gradient for 2nd layer weights are:\\n\",gw2.numpy())\n","    print(\"--------------------------------------------------\")\n","    print(\" the gradient for 1st layer bias are:\\n\",gb1.numpy())\n","    print(\"--------------------------------------------------\")\n","    print(\" the gradient for 2nd layer bias are:\\n\",gb2.numpy())\n","    print(\"--------------------------------------------------\")\n","\n","    # Gradient descent:\n","    lr=0.2\n","    w1.assign_sub(lr*gw1)\n","    b1.assign_sub(lr*gb1) \n","    w2.assign_sub(lr*gw2)\n","    b2.assign_sub(lr*gb2)\n","    print(\"**************************************************\")\n","    print(\"NEW UPDATES\")\n","    print(\"**************************************************\")\n","    print(\" the updated 1st layer weights are:\\n\",w1.numpy())\n","    print(\"--------------------------------------------------\")\n","    print(\" the updated 2nd layer weights are:\\n\",w2.numpy())\n","    print(\"--------------------------------------------------\")\n","    print(\" the updated 1st layer bias are:\\n\",b1.numpy())\n","    print(\"--------------------------------------------------\")\n","    print(\" the updated 2nd layer bias are:\\n\",b2.numpy())\n","\n","\n","    return w1, b1, w2, b2,loss\n","\n","```"]},{"cell_type":"code","execution_count":19,"id":"72ab0367-85da-46b9-bce9-4da2c72dfaa7","metadata":{"id":"72ab0367-85da-46b9-bce9-4da2c72dfaa7","outputId":"d50e1675-e868-44fd-b708-a0459249cadd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stdout","output_type":"stream","text":["16/16 [==============================] - 1s 5ms/step - loss: 111.4731\n","Epoch 2/10\n","16/16 [==============================] - 0s 5ms/step - loss: 32.0273\n","Epoch 3/10\n","16/16 [==============================] - 0s 7ms/step - loss: 6.4743\n","Epoch 4/10\n","16/16 [==============================] - 1s 49ms/step - loss: 1.3505\n","Epoch 5/10\n","16/16 [==============================] - 0s 3ms/step - loss: 0.4504\n","Epoch 6/10\n","16/16 [==============================] - 0s 3ms/step - loss: 0.2717\n","Epoch 7/10\n","16/16 [==============================] - 0s 3ms/step - loss: 0.2170\n","Epoch 8/10\n","16/16 [==============================] - 0s 3ms/step - loss: 0.1933\n","Epoch 9/10\n","16/16 [==============================] - 0s 3ms/step - loss: 0.1796\n","Epoch 10/10\n","16/16 [==============================] - 0s 3ms/step - loss: 0.1702\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x20e59eb6560>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(X,Y.values,epochs=10,batch_size=32)"]},{"cell_type":"code","execution_count":20,"id":"ac6189a0-f5a7-48e3-9bbd-03f219c6ab2c","metadata":{"id":"ac6189a0-f5a7-48e3-9bbd-03f219c6ab2c","outputId":"fccf1023-1b62-450d-9d92-0870bf5f9d9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["16/16 [==============================] - 0s 3ms/step\n"]},{"data":{"text/plain":["array([12.918899 , 13.371866 , 13.059525 , 13.074423 , 13.056641 ,\n","       12.807037 , 12.929087 , 13.21512  , 13.158388 , 12.951017 ,\n","       13.010309 , 13.251373 , 13.139977 , 12.850607 , 13.253237 ,\n","       12.881327 , 12.977032 , 13.281887 , 12.926731 , 12.87582  ,\n","       13.122843 , 12.931965 , 13.019533 , 13.218692 , 12.972275 ,\n","       13.093056 , 13.145569 , 13.114955 , 13.236519 , 13.188223 ,\n","       12.961715 , 13.241293 , 13.0279455, 13.234451 , 13.355352 ,\n","       13.285514 , 12.784373 , 13.042053 , 13.065953 , 13.151102 ,\n","       12.979461 , 12.940183 , 12.798605 , 13.024098 , 12.894661 ,\n","       12.870279 , 13.068082 , 13.059525 , 12.900324 , 13.31181  ,\n","       13.21512  , 13.238161 , 13.206583 , 13.030889 , 13.108124 ,\n","       13.051939 , 13.112807 , 13.373259 , 12.913634 , 12.993294 ,\n","       13.31181  , 13.201647 , 13.218692 , 13.177898 , 13.251373 ,\n","       12.812614 , 12.996238 , 12.827591 , 13.185545 , 13.115052 ,\n","       13.181805 , 13.228926 , 13.131874 , 13.053028 , 12.916271 ,\n","       12.909611 , 13.108488 , 13.218692 , 13.097561 , 13.169125 ,\n","       13.06826  , 13.362962 , 13.163848 , 13.030889 , 13.144259 ,\n","       13.090012 , 12.876846 , 12.954805 , 12.943359 , 12.892141 ,\n","       13.300264 , 13.107151 , 13.250454 , 13.143712 , 12.974595 ,\n","       13.221201 , 13.003309 , 13.285095 , 12.9370575, 13.4189   ,\n","       13.29261  , 13.076522 , 12.916271 , 13.150355 , 13.01619  ,\n","       13.249708 , 13.086445 , 13.435465 , 12.795775 , 12.872204 ,\n","       12.915291 , 13.1381   , 12.83917  , 13.183039 , 13.072853 ,\n","       12.80297  , 13.120906 , 12.787237 , 13.30192  , 13.00096  ,\n","       13.063637 , 12.947249 , 13.842195 , 13.04866  , 13.04866  ,\n","       12.9370575, 12.940183 , 12.876846 , 13.057366 , 13.249708 ,\n","       13.285514 , 12.97215  , 13.069752 , 13.109984 , 13.023181 ,\n","       13.136031 , 13.030889 , 13.072853 , 13.028633 , 13.164332 ,\n","       13.061675 , 12.881978 , 13.324577 , 13.443249 , 12.977275 ,\n","       12.989096 , 12.936544 , 13.257495 , 13.47258  , 12.984489 ,\n","       13.166301 , 12.929208 , 12.866482 , 12.921518 , 13.10414  ,\n","       12.957308 , 13.074423 , 12.84802  , 12.761137 , 13.062326 ,\n","       12.979461 , 13.095354 , 12.889682 , 12.991485 , 13.320368 ,\n","       13.044825 , 12.951017 , 12.812614 , 12.83917  , 12.897635 ,\n","       13.350073 , 13.133957 , 13.232725 , 12.996238 , 12.993866 ,\n","       13.042053 , 13.07056  , 12.9370575, 12.945618 , 13.163786 ,\n","       12.827591 , 12.899677 , 13.142418 , 13.115091 , 13.166301 ,\n","       13.2803335, 13.084199 , 13.042053 , 13.032808 , 13.369175 ,\n","       12.939617 , 12.962288 , 13.101152 , 13.33693  , 12.991485 ,\n","       13.028633 , 13.07056  , 13.127688 , 13.269295 , 12.91099  ,\n","       13.385978 , 13.37163  , 13.276453 , 13.253237 , 13.247197 ,\n","       12.99982  , 13.295623 , 13.209715 , 12.88952  , 13.2204685,\n","       13.321776 , 12.856272 , 13.005564 , 13.053028 , 12.820915 ,\n","       13.0056505, 12.939617 , 13.474615 , 13.070203 , 12.884531 ,\n","       13.115052 , 12.764405 , 12.954805 , 13.249568 , 13.203299 ,\n","       13.347443 , 12.900324 , 13.47258  , 13.270889 , 12.8730545,\n","       13.072211 , 12.821746 , 13.162357 , 13.447056 , 12.894939 ,\n","       12.969697 , 12.984295 , 12.856272 , 13.039836 , 13.174408 ,\n","       13.201647 , 13.388246 , 13.158384 , 13.0031395, 13.088966 ,\n","       13.02182  , 13.003309 , 12.975564 , 13.38719  , 13.030381 ,\n","       12.934488 , 13.046466 , 13.65469  , 12.850682 , 13.208218 ,\n","       12.827591 , 12.979461 , 13.195014 , 13.057366 , 13.143712 ,\n","       12.869581 , 13.177969 , 13.285514 , 13.163786 , 12.842668 ,\n","       12.790092 , 13.155427 , 13.024098 , 12.929087 , 13.065953 ,\n","       13.311089 , 13.165434 , 13.433231 , 13.1381   , 12.985282 ,\n","       13.204251 , 13.044825 , 13.113087 , 13.080698 , 13.128615 ,\n","       12.986699 , 12.772827 , 12.995477 , 12.991485 , 13.364563 ,\n","       13.245705 , 13.061675 , 12.9370575, 12.836288 , 12.790092 ,\n","       12.81539  , 13.386149 , 13.110651 , 12.984295 , 12.959802 ,\n","       12.918899 , 13.044263 , 13.177898 , 12.850682 , 12.929325 ,\n","       12.993866 , 13.269424 , 13.101954 , 13.02182  , 12.998603 ,\n","       13.03761  , 13.117096 , 12.942904 , 12.897635 , 13.449163 ,\n","       13.388309 , 12.879416 , 13.205349 , 13.153251 , 12.985738 ,\n","       12.790092 , 12.973313 , 13.093056 , 13.296937 , 13.005657 ,\n","       13.00096  , 13.185612 , 13.276453 , 12.894939 , 13.075138 ,\n","       13.206079 , 12.834576 , 13.065953 , 12.761137 , 12.931485 ,\n","       13.043664 , 13.099762 , 13.025502 , 13.106411 , 13.0056505,\n","       13.061675 , 13.14016  , 13.084199 , 13.32597  , 13.125585 ,\n","       12.931911 , 12.855983 , 12.957308 , 13.172166 , 13.159756 ,\n","       13.122843 , 13.057366 , 13.050849 , 13.125585 , 12.909611 ,\n","       12.829138 , 13.308915 , 13.07056  , 12.845348 , 13.032808 ,\n","       13.070203 , 13.356571 , 12.899677 , 13.131874 , 13.158388 ,\n","       13.23968  , 13.131874 , 12.962288 , 12.809949 , 12.878578 ,\n","       12.91099  , 13.23273  , 13.019533 , 12.913634 , 13.1682625,\n","       12.892234 , 12.897635 , 13.230142 , 13.378882 , 12.969697 ,\n","       12.975564 , 12.949776 , 12.931911 , 13.1949835, 12.981881 ,\n","       13.049576 , 13.077569 , 12.9370575, 12.869085 , 12.801424 ,\n","       13.136217 , 12.845348 , 12.834576 , 13.424381 , 12.993866 ,\n","       13.377686 , 13.229254 , 13.010668 , 12.926441 , 13.042053 ,\n","       12.829138 , 13.167351 , 13.370405 , 13.195014 , 12.931911 ,\n","       13.127688 , 13.1702175, 12.787237 , 12.985282 , 13.251642 ,\n","       12.761137 , 12.931911 , 12.945982 , 13.037593 , 13.095091 ,\n","       12.842043 , 12.959802 , 13.063637 , 12.9370575, 13.366704 ,\n","       13.112807 , 13.057366 , 12.870279 , 13.550955 , 13.07056  ,\n","       13.10697  , 13.347382 , 13.2378845, 12.879416 , 13.2803335,\n","       12.939617 , 13.162357 , 13.054295 , 12.998603 , 12.934488 ,\n","       13.206079 , 13.07056  , 13.099762 , 12.922041 , 13.019533 ,\n","       13.133326 , 12.94571  , 13.056641 , 12.9370575, 12.9241295,\n","       12.886798 , 13.236171 , 13.374065 , 13.142213 , 13.326308 ,\n","       12.937452 , 13.27406  , 12.833398 , 13.054295 , 13.026369 ,\n","       13.074423 , 13.0056505, 13.535563 , 12.908336 , 13.156387 ,\n","       12.879416 , 13.1381   , 13.218692 , 13.2378845, 12.845348 ,\n","       12.918899 , 13.343618 , 13.651767 , 12.824088 , 13.279928 ,\n","       13.101152 , 13.17989  , 13.056641 , 12.921518 , 13.1063175,\n","       12.926731 , 13.523667 , 13.236171 , 13.076522 , 13.310365 ,\n","       12.899677 , 13.012627 , 12.796675 , 12.974595 , 13.181364 ,\n","       13.468767 , 12.897174 , 13.371866 , 13.109137 , 13.183711 ,\n","       12.81539  , 13.261237 , 13.097561 , 13.332858 , 13.168325 ,\n","       13.115052 , 13.005657 , 13.23968  , 12.821746 , 13.270889 ,\n","       13.476636 , 12.926731 , 13.061675 , 12.836288 ], dtype=float32)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["model.predict(X)[:,0]"]},{"cell_type":"code","execution_count":null,"id":"e70387c2-c04d-4ff1-8bc1-a13a064daf6a","metadata":{"id":"e70387c2-c04d-4ff1-8bc1-a13a064daf6a"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"nn_keras.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}
